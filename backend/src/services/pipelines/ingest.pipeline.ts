import { supabase } from '../../config/supabase';
import { logger } from '../../utils/logger';
// Removed pdf-parse and mammoth - now using LlamaParse
import axios from 'axios';
import { IngestPipelineInput, IngestPipelineOutput } from '../../../../shared/types';
import { parseResumeFromBuffer } from '../llm/llamaparse.service';

/**
 * Get or create company by canonical name
 */
async function getOrCreateCompanyId(canonicalName: string): Promise<string> {
  try {
    // Try to find existing company by canonical name
    const { data: existing } = await supabase
      .from('companies')
      .select('id')
      .eq('canonical_name', canonicalName)
      .maybeSingle();

    if (existing) {
      logger.info('Found existing company', { canonicalName, id: existing.id });
      return existing.id;
    }

    // Create new company
    const { data: created, error } = await supabase
      .from('companies')
      .insert({
        tenant_id: null, // Will be set when multi-tenancy is implemented
        canonical_name: canonicalName,
      })
      .select()
      .single();

    if (error) {
      logger.error('Failed to create company', { error, canonicalName });
      throw error;
    }

    logger.info('Created new company', { canonicalName, id: created.id });
    return created.id;
  } catch (error) {
    logger.error('getOrCreateCompanyId failed', { error, canonicalName });
    throw error;
  }
}

/**
 * Run ingestion pipeline
 * Extracts text from resume and structures it into work experiences, achievements, and skills
 */
export async function runIngestPipeline(userId: string, documentId: string): Promise<void> {
  try {
    logger.info('Starting ingestion pipeline', { userId, documentId });

    // Get document
    const { data: document, error: docError } = await supabase
      .from('documents')
      .select('*')
      .eq('id', documentId)
      .eq('user_id', userId)
      .single();

    if (docError || !document) {
      throw new Error('Document not found');
    }

    // Download document
    const response = await axios.get(document.storage_url, {
      responseType: 'arraybuffer',
      timeout: 30000,
    });

    const buffer = Buffer.from(response.data);

    // Parse resume with LlamaParse (handles PDF, DOCX, etc. automatically)
    logger.info('Parsing resume with LlamaParse', { userId, documentId });
    const structured = await parseResumeFromBuffer(buffer, document.file_name || 'resume.pdf');

    // Update document with extracted text
    await supabase
      .from('documents')
      .update({ extracted_text: structured.raw_text })
      .eq('id', documentId);

    logger.info('LlamaParse completed', {
      userId,
      textLength: structured.raw_text.length,
    });

    // Save work experiences and achievements (linked together)
    let workExperiencesCreated = 0;
    let achievementsCreated = 0;

    if (structured.work_experiences && structured.work_experiences.length > 0) {
      for (const exp of structured.work_experiences) {
        // Get or create company
        const companyId = await getOrCreateCompanyId(exp.company_name);

        // Insert work experience with correct schema
        const { data: workExp, error: weError } = await supabase
          .from('work_experiences')
          .insert({
            user_id: userId,
            company_id: companyId,
            title: exp.role_title, // Map role_title → title
            start_date: exp.start_date,
            end_date: exp.end_date,
            description: exp.description,
            location: null, // Can be extracted later if needed
          })
          .select()
          .single();

        if (weError) {
          logger.error('Failed to insert work experience', { error: weError, exp });
          continue;
        }

        workExperiencesCreated++;

        // Find achievements for this role (match by scope/company name)
        const relatedAchievements = structured.achievements.filter(
          (a) =>
            a.scope?.toLowerCase().includes(exp.company_name.toLowerCase()) ||
            a.raw_text?.toLowerCase().includes(exp.company_name.toLowerCase())
        );

        // Insert achievements linked to this work experience
        for (const achievement of relatedAchievements) {
          const { error: achError } = await supabase.from('achievements').insert({
            work_experience_id: workExp.id, // Link to work experience
            source_document_id: documentId,
            raw_text: achievement.raw_text,
            metric_value_numeric: achievement.metric_value, // Map metric_value → metric_value_numeric
            metric_unit: achievement.metric_unit,
            metric_label: achievement.scope || 'general', // Use scope as label
            impact_statement: null, // Will be generated by achievements pipeline
            provenance: 'user_provided',
            confidence: achievement.metric_value ? 1.0 : 0.6,
            requires_review: !achievement.metric_value,
          });

          if (!achError) achievementsCreated++;
        }
      }
    }

    // Handle achievements without clear work experience link
    const unmatchedAchievements = structured.achievements.filter(
      (a) =>
        !structured.work_experiences.some(
          (exp) =>
            a.scope?.toLowerCase().includes(exp.company_name.toLowerCase()) ||
            a.raw_text?.toLowerCase().includes(exp.company_name.toLowerCase())
        )
    );

    if (unmatchedAchievements.length > 0 && structured.work_experiences.length > 0) {
      // Link to most recent work experience
      const { data: recentExp } = await supabase
        .from('work_experiences')
        .select('id')
        .eq('user_id', userId)
        .order('start_date', { ascending: false })
        .limit(1)
        .single();

      if (recentExp) {
        for (const achievement of unmatchedAchievements) {
          const { error } = await supabase.from('achievements').insert({
            work_experience_id: recentExp.id,
            source_document_id: documentId,
            raw_text: achievement.raw_text,
            metric_value_numeric: achievement.metric_value,
            metric_unit: achievement.metric_unit,
            metric_label: achievement.scope || 'general',
            impact_statement: null,
            provenance: 'user_provided',
            confidence: achievement.metric_value ? 1.0 : 0.6,
            requires_review: true, // Mark for review since unclear which role
          });

          if (!error) achievementsCreated++;
        }
      }
    }

    // Save skills
    let skillsCreated = 0;
    if (structured.skills && structured.skills.length > 0) {
      for (const skill of structured.skills) {
        const { error } = await supabase.from('skills').insert({
          user_id: userId,
          skill_name: skill.skill_name,
          category: skill.category || 'general',
          proficiency_level: skill.proficiency_level || 'intermediate',
        });

        if (!error) skillsCreated++;
      }
    }

    logger.info('Ingestion pipeline completed', {
      userId,
      documentId,
      workExperiencesCreated,
      achievementsCreated,
      skillsCreated,
      companiesProcessed: structured.companies.length,
    });
  } catch (error: any) {
    logger.error('Ingestion pipeline failed', {
      error: error.message,
      stack: error.stack,
      userId,
      documentId,
    });
    throw error;
  }
}
